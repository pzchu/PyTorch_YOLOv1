{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "print(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意观察下面的代码，你的输入需要按照batch channel w h 来设置。\n",
    "- pandding=0 不是说不补，而是说你的输入输出是一致的，而当你设置padding=1的时候，那就意味着你的输出比你的输入大一圈。\n",
    "- 可以通过实验感受下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand(1,3,4,4)\n",
    "conv1 = torch.nn.Conv2d(3,2,1,1,1)\n",
    "conv1(t1),conv1.bias,conv1.weight\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接下来我们感受下什么是BN\n",
    "- BN操作针对的是通道这个要注意，所以有个参数要设置对。\n",
    "- 直接求var的时候 要考虑有偏和无偏，什么是var的有偏估计呢？有偏分母就是n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.]],\n",
       "\n",
       "         [[13., 14., 15., 16.],\n",
       "          [17., 18., 19., 20.],\n",
       "          [21., 22., 23., 24.]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.arange(1,25,dtype=torch.float32)\n",
    "t3 = t2.reshape(1,2,3,4)\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5933, -1.3036, -1.0139, -0.7242],\n",
       "          [-0.4345, -0.1448,  0.1448,  0.4345],\n",
       "          [ 0.7242,  1.0139,  1.3036,  1.5933]],\n",
       "\n",
       "         [[-1.5933, -1.3036, -1.0139, -0.7242],\n",
       "          [-0.4345, -0.1448,  0.1448,  0.4345],\n",
       "          [ 0.7242,  1.0139,  1.3036,  1.5933]]]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = nn.BatchNorm2d(2)\n",
    "bn(t3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.running_mean, bn.running_var,bn.weight,bn.bias\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.9167)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(13,25,dtype=torch.float32)\n",
    "\n",
    "sum((t-18.5)**2) / 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.0694, -4.7797, -4.4901, -4.2004],\n",
       "          [-3.9107, -3.6210, -3.3313, -3.0417],\n",
       "          [-2.7520, -2.4623, -2.1726, -1.8829]],\n",
       "\n",
       "         [[-1.5932, -1.3036, -1.0139, -0.7242],\n",
       "          [-0.4345, -0.1448,  0.1448,  0.4345],\n",
       "          [ 0.7242,  1.0139,  1.3036,  1.5932]]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t3-18.5)/(11.9167**0.5+0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spp中的pool操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128, 16, 16])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3,64,16,16)\n",
    "x1 = f.max_pool2d(x,9,stride=1,padding=4)\n",
    "x2 = f.max_pool2d(x,5,stride=1,padding=2)\n",
    "torch.cat([x1,x2],dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看下什么是残差块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 16, 16])\n",
      "torch.Size([3, 64, 16, 16])\n",
      "torch.Size([3, 64, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 16, 16])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        print(identity.shape)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        print(out.shape)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        print(out.shape)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "model = BasicBlock(64,64)\n",
    "model(x).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'conv1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m      2\u001b[0m         identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m----> 4\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m(x)\n\u001b[0;32m      5\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m      6\u001b[0m         out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'conv1'"
     ]
    }
   ],
   "source": [
    "forward(nn, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "你好啊\n",
    "这是个一个test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
